<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CS180 Project 2 — Fun with Filters & Frequencies: https://eduardo1100.github.io/CS180/2/index.html</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
  <style>
    :root{
      --bg:#0b0c10; --panel:#11131a; --text:#eaeef5; --muted:#9aa4b2; --accent:#7aa2ff; --border:#1d2230;
      --radius:16px; --gap:18px; --shadow:0 10px 30px rgba(0,0,0,.25);
    }
    @media (prefers-color-scheme: light){
      :root{ --bg:#f6f8fb; --panel:#ffffff; --text:#0b0c10; --muted:#586174; --accent:#335dff; --border:#e9edf5; }
    }
    *{ box-sizing:border-box; }
    body{ margin:0; font-family:Inter,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif; background:var(--bg); color:var(--text); }
    header{ position:sticky; top:0; z-index:5; backdrop-filter:saturate(180%) blur(8px); background:color-mix(in oklab, var(--bg) 70%, transparent); border-bottom:1px solid var(--border); }
    .wrap{ max-width:1000px; margin:0 auto; padding:24px; }
    h1{ font-size:clamp(24px,3.8vw,40px); margin:6px 0 8px; letter-spacing:-.02em; }
    h2{ font-size:clamp(18px,2.6vw,28px); margin:32px 0 10px; letter-spacing:-.01em; }
    h3{ font-size:clamp(16px,2.2vw,22px); margin:24px 0 8px; }
    p,li{ line-height:1.6; color:var(--text); }
    .pill{ display:inline-block; padding:6px 10px; border:1px solid var(--border); border-radius:999px; color:var(--muted); font-size:12px; }
    .panel{ background:var(--panel); border:1px solid var(--border); border-radius:var(--radius); box-shadow:var(--shadow); padding:20px; }
    .grid{ display:grid; gap:var(--gap); }
    .g-2{ grid-template-columns: 1fr; }
    .g-3{ grid-template-columns: 1fr; }
    .g-4{ grid-template-columns: repeat(4, minmax(0,1fr)); }
    .fig{ background:var(--panel); border:1px solid var(--border); border-radius:12px; overflow:hidden; }
    .fig img{ display:block; width:100%; height:auto; }
    .cap{ padding:10px 12px; font-size:13px; color:var(--muted); border-top:1px solid var(--border); }
    code,pre{ font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
    pre{ background:#0e1117; color:#e6edf3; border:1px solid #1f2937; border-radius:12px; padding:14px; overflow:auto; }
    .toc a{ color:var(--text); text-decoration:none; }
    .toc a:hover{ color:var(--accent); }
    .callout{ border-left:3px solid var(--accent); padding:10px 14px; background:color-mix(in oklab, var(--accent) 10%, var(--panel)); border-radius:12px; }
    footer{ color:var(--muted); font-size:13px; padding:24px 0 40px; }
    .kbd{ border:1px solid var(--border); background:color-mix(in oklab, var(--panel) 70%, #0000); padding:2px 6px; border-radius:6px; font-size:12px; }
  </style>
</head>
<body>
  <header>
    <div class="wrap">
      <div class="pill">CS180 • Fall 2025</div>
      <h1>Project 2 — Fun with Filters & Frequencies</h1>
      <p style="margin:4px 0 0">Eduardo Cortes — UC Berkeley</p>
    </div>
  </header>

  <main class="wrap">

    <section class="panel">
      <h2>Overview</h2>
      <p>This project explores 2D convolution, finite-difference gradients, derivatives of Gaussians (DoG), unsharp masking, hybrid images, and multi‑resolution blending. I implement convolution from scratch, analyze edge detection with/without Gaussian smoothing, create hybrid images following Oliva–Torralba–Schyns, and reproduce the classic <em>oraple</em> blend using Gaussian/Laplacian stacks and mask pyramids.</p>
    </section>

    <section class="panel">
      <h2>Table of Contents</h2>
      <ol class="toc">
        <li><a href="#p11">Part 1.1 — Convolutions from Scratch</a></li>
        <li><a href="#p12">Part 1.2 — Finite Difference & Gradient Magnitude</a></li>
        <li><a href="#p13">Part 1.3 — Derivative of Gaussian (DoG)</a></li>
        <li><a href="#p21">Part 2.1 — Image Sharpening (Unsharp Mask)</a></li>
        <li><a href="#p22">Part 2.2 — Hybrid Images</a></li>
        <li><a href="#p23">Part 2.3 — Gaussian & Laplacian Stacks</a></li>
        <li><a href="#p24">Part 2.4 — Multiresolution Blending (Oraple)</a></li>
      </ol>
    </section>

    <!-- Part 1.1 -->
    <section id="p11" class="panel">
      <h2>Part 1.1 — Convolutions from Scratch</h2>
      <p>I implemented 2D convolution with explicit loops (4‑loop baseline, then 2‑loop optimization) and matched SciPy’s <code>convolve2d</code> with zero padding. Below I show the self‑portrait and the 9×9 box‑filtered result.</p>
      <div class="grid g-2">
        <figure class="fig">
          <img src="media/1.1_me.png" alt="Self portrait grayscale" />
          <figcaption class="cap">Grayscale input self‑portrait.</figcaption>
        </figure>
        <figure class="fig">
          <img src="media/1.1_box.png" alt="Box filter comparison (1x3)" />
          <figcaption class="cap">9×9 box filtering (naive = optimized = SciPy verification).</figcaption>
        </figure>
        <figure class="fig">
          <img src="media/1.1_diffops.png" alt="Finite difference (SciPy vs optimized)" />
          <figcaption class="cap">Finite Difference Operators (optimized = SciPy verification)</figcaption>
        </figure>
      </div>

<details>
  <summary><strong>Code — Part 1.1 Convolution from Scratch</strong></summary>
  <pre><code>def convolution_4(img, kernel):
    kernel = np.flip(kernel, axis=(0,1))

    img_h, img_w = img.shape
    ker_h, ker_w = kernel.shape

    pad_h, pad_w = ker_h // 2, ker_w //2
    pad_img = np.pad(img, ((pad_h, pad_h),(pad_w, pad_w)), mode="constant")
    pad_img_h, pad_img_w = pad_img.shape

    conv_img = np.zeros_like(img, dtype=np.float64)
    for i in range(img_h):
        for j in range(img_w):
            for k in range(ker_h):
                for l in range(ker_w):
                     conv_img[i,j] += pad_img[i+k, j+l] * kernel[k,l]
    return conv_img


def convolution_2(img, kernel):
    kernel = np.flip(kernel, axis=(0,1))

    img_h, img_w = img.shape
    ker_h, ker_w = kernel.shape

    pad_h, pad_w = ker_h // 2, ker_w //2
    pad_img = np.pad(img, ((pad_h, pad_h),(pad_w, pad_w)), mode="constant")
    pad_img_h, pad_img_w = pad_img.shape

    conv_img = np.zeros_like(img, dtype=np.float64)
    for i in range(img_h):
        for j in range(img_w):
            conv_img[i,j] = np.sum(pad_img[i:i+ker_h, j:j+ker_w] * kernel)
    return conv_img
  </code></pre>
</details>
</section>
<!-- Part 1.2 -->
    <section id="p12" class="panel">
      <h2>Part 1.2 — Gradient Magnitude</h2>
      <p>I computed partial derivatives using finite difference operators <code>D<sub>x</sub>=[-1,1]</code> and <code>D<sub>y</sub>=[-1;1]</code>, formed the gradient magnitude, and thresholded to get a binarized edge map.</p>
      <div class="grid g-3">
        <figure class="fig"><img src="media/1.2_binarized_grad_mag.png" alt="Binarized gradient magnitude (1x3)" /><figcaption class="cap">Choosing a threshold trades off noise vs missed edges.</figcaption></figure>
      </div>
    
<details>
  <summary><strong>Code — Part 1.2 Finite Differences & Gradient Magnitude</strong></summary>
  <pre><code>def gradient_magnitude_img(Dx_img, Dy_img):
    grad_mag_img = np.sqrt(Dx_img**2 + Dy_img**2)
    return grad_mag_img / grad_mag_img.max()

img = np.array(Image.open("cameraman.png").convert("L"))
Dx = np.array([[-1, 1]], dtype=np.float64)
Dy = np.array([[-1], [1]], dtype=np.float64)

Dx_img = convolve2d(img, Dx, mode="same", boundary="symm")
Dy_img = convolve2d(img, Dy, mode="same", boundary="symm")
grad_mag_img = gradient_magnitude_img(Dx_img, Dy_img)

grad_mag_img_binarized = grad_mag_img.copy()
grad_mag_img_binarized[grad_mag_img_binarized < 0.07] = 0
grad_mag_img_binarized[grad_mag_img_binarized >= 0.07] = 1
  </code></pre>
</details>
</section>
<!-- Part 1.3 -->
    <section id="p13" class="panel">
      <h2>Part 1.3 — Derivative of Gaussian (DoG)</h2>
      <p>I first smoothed with a Gaussian then applied finite differences; next I created DoG filters by convolving the Gaussian kernel with <code>D<sub>x</sub>, D<sub>y</sub></code> to achieve the same result with a single convolution. The DoG pipeline suppresses noise while preserving edges.</p>
      <div class="grid g-3">
        <figure class="fig"><img src="media/1.3_DoG.png" alt="DoG results (1x3)" /><figcaption class="cap">Gaussian smoothing → gradients → magnitude.</figcaption></figure>
        <figure class="fig"><img src="media/1.3_kernels.png" alt="Kernels visualization (1x3)" /><figcaption class="cap">Gaussian / DoG<sub>x</sub> / DoG<sub>y</sub> kernels.</figcaption></figure>
        <figure class="fig"><img src="media/1.3_filters.png" alt="DoG filters as images (1x3)" /><figcaption class="cap">DoG filters visualized.</figcaption></figure>
      </div>
      <div class="grid g-2" style="margin-top:var(--gap)">
        <figure class="fig"><img src="media/1.3_DoG_single_conv.png" alt="Single-convolution DoG vs two-step (1x2)" /><figcaption class="cap">Single‑conv DoG ≈ blur+diff (verification).</figcaption></figure>
      </div>
    
<details>
  <summary><strong>Code — Part 1.3 Gaussian & DoG</strong></summary>
  <pre><code>gaussian_kernel_1D = getGaussianKernel(17, 1)
gaussian_kernel_2D = gaussian_kernel_1D @ gaussian_kernel_1D.T

Dx = np.array([[-1, 1]], dtype=np.float64)
Dy = np.array([[-1], [1]], dtype=np.float64)
gaussian_kernel_Dx = convolve2d(gaussian_kernel_2D, Dx, mode="same", boundary="symm")
gaussian_kernel_Dy = convolve2d(gaussian_kernel_2D, Dy, mode="same", boundary="symm")

guassian_img = convolve2d(img, gaussian_kernel_2D, mode="same", boundary="symm")
gaussian_Dx_img = convolve2d(img, gaussian_kernel_Dx, mode="same", boundary="symm")
guassian_Dy_img = convolve2d(img, gaussian_kernel_Dy, mode="same", boundary="symm")
  </code></pre>
</details>
</section>
<!-- Part 2.1 -->
    <section id="p21" class="panel">
      <h2>Part 2.1 — Image Sharpening (Unsharp Mask)</h2>
      <p>Unsharp masking adds back a scaled high‑frequency residue: <code>I<sub>sharp</sub> = I + α (I − Gσ*I)</code>. I experimented with σ and α on Taj Mahal and another image; DoG‑style sharpening emphasizes edges even more but can introduce halos for large α.</p>
      <div class="grid g-3">
        <figure class="fig"><img src="media/2.1_taj_sharpening.png" alt="Taj unsharp triptych" /><figcaption class="cap">Taj: original • unsharp kernel • sharpened.</figcaption></figure>
        <figure class="fig"><img src="media/2.1_dog_sharpening.png" alt="DoG sharpening triptych" /><figcaption class="cap">Dog: original • blurred • sharpened blurred.</figcaption></figure>
      </div>
    
<details>
  <summary><strong>Code — Part 2.1 Unsharp Mask</strong></summary>
  <pre><code>gaussian_kernel_1D = getGaussianKernel(9, 3)
gaussian_kernel_2D = gaussian_kernel_1D @ gaussian_kernel_1D.T
unit_impulse_kernel = np.zeros_like(gaussian_kernel_2D, dtype=np.float64)
unit_impulse_kernel[unit_impulse_kernel.shape[0] // 2, unit_impulse_kernel.shape[1] // 2] = 1
alpha = 2
unsharp_kernel = (1+alpha)*unit_impulse_kernel - alpha*gaussian_kernel_2D

img = np.array(Image.open("taj.jpg").convert("L"))
unsharp_img = convolve2d(img, unsharp_kernel, mode="same", boundary="symm")
unsharp_img = np.clip(unsharp_img, 0, 255).astype(np.uint8)

img2 = np.array(Image.open("dog.jpg").convert("L"))
img2 = downsample(img2, 8)
gaussian_img2 = convolve2d(img2, gaussian_kernel_2D, mode="same", boundary="symm")
unsharp_img2 = convolve2d(gaussian_img2, unsharp_kernel, mode="same", boundary="symm")
unsharp_img2 = np.clip(unsharp_img2, 0, 255).astype(np.uint8)
  </code></pre>
</details>
</section>
<!-- Part 2.2 -->
    <section id="p22" class="panel">
      <h2>Part 2.2 — Hybrid Images</h2>
      <p>I align two images with clicked correspondences, low‑pass one and high‑pass the other, then sum. I also visualize the log‑magnitude Fourier spectra of each component and the final hybrid.</p>

      <div class="grid g-3">
        <figure class="fig"><img src="media/2.2_Black Hole_Quantum Computer.png" alt="Blackhole + QC hybrid" /><figcaption class="cap">Hybrid: black hole ⊕ quantum computer</figcaption></figure>
        <figure class="fig"><img src="media/2.2_Black Hole+Quantum Computer_FT.png" alt="FT triptych (1x3)" /><figcaption class="cap">Log FT: hybrid.</figcaption></figure>
        <figure class="fig"><img src="media/2.2_Black Hole_Quantum Computer_FT.png" alt="FT triptych (1x3)" /><figcaption class="cap">Log FT: inputs.</figcaption></figure>
        <figure class="fig"><img src="media/2.2_Black Hole_Quantum Computer_filtered_FT.png" alt="Filtered FTs (1x2)" /><figcaption class="cap">Log FT: filtered inputs.</figcaption></figure>
      </div>

      <div class="grid g-3" style="margin-top:var(--gap)">
        <figure class="fig"><img src="media/2.2_bull_tiger.png" alt="Bull/Tiger hybrid" /><figcaption class="cap">Hybrid: bull ⊕ tiger.</figcaption></figure>
        <figure class="fig"><img src="media/2.2_galaxy_flower.png" alt="Galaxy/Flower hybrid" /><figcaption class="cap">Hybrid: galaxy ⊕ flower.</figcaption></figure>
      </div>

<details>
  <summary><strong>Code — Part 2.2 Hybrid Images</strong></summary>
  <pre><code>def hybrid_image(img1, img2, sigma1, sigma2):
    img1_low  = gaussian_filter(img1, sigma=(sigma1, sigma1, 0))
    img2_high = img2 - gaussian_filter(img2, sigma=(sigma2, sigma2, 0))

    return np.clip(img1_low + img2_high, 0.0, 1.0)

sigma1 = .5
sigma2 = 5
hybrid = hybrid_image(im1, im2, sigma1, sigma2)
  </code></pre>
</details>
    </section>

    <!-- Part 2.3 -->
    <section id="p23" class="panel">
      <h2>Part 2.3 — Gaussian & Laplacian Stacks</h2>
      <p><em>Placeholder:</em> Results and code to be added.</p>
      <div class="grid g-2">
        <figure class="fig"><img class="wide zoomable" src="media/2.3_gaussian_stack_apple.png" alt="Gaussian stack visualization" /><figcaption class="cap">Gaussian stack slices for masked apple.</figcaption></figure>
        <figure class="fig"><img class="wide zoomable" src="media/2.3_laplacian_stack_apple.png" alt="Laplacian stack visualization" /><figcaption class="cap">Laplacian stack slices for masked apple.</figcaption></figure>
        <figure class="fig"><img class="wide zoomable" src="media/2.3_gaussian_stack_orange.png" alt="Gaussian stack visualization" /><figcaption class="cap">Gaussian stack slices for masked orange</figcaption></figure>
        <figure class="fig"><img class="wide zoomable" src="media/2.3_laplacian_stack_orange.png" alt="Laplacian stack visualization" /><figcaption class="cap">Laplacian stack slices for masked orange</figcaption></figure>
      </div>
    </section>

    <details>
      <summary><strong>Code  — Part 2.3 Gaussian/Laplacian Stack and Horizontal Mask</strong></summary>
      <pre><code class="language-python">def get_gaussian_stack(img, levels=5, sigma=5):
        gaussian_stack = [img]
        for _ in range(1, levels):
            guassian_stack.append(gaussian_filter(guassian_stack[-1], sigma=(sigma, sigma, 0)))
        return guassian_stack
        
        def get_laplacian_stack(img, levels=5, sigma=5):
            gaussian_stack = get_gaussian_stack(img, levels, sigma)
            laplacian_stack = [gaussian_stack[i] - gaussian_stack[i+1] for i in range(levels-1)] + [gaussian_stack[-1]]
            return gaussian_stack, laplacian_stack
        
        def get_horizontal_mask(img, direction='right'):
          h, w = img.shape[:2]
          if direction == 'right':
            mask = np.zeros((h, w), np.float32)
            mask[:, :w//2] = 1.0
          else:
            mask = np.ones((h, w), np.float32)
            mask[:, :w//2] = 0
          mask = gaussian_filter(mask, sigma=40)
          return np.dstack([mask, mask, mask])
    </code></pre>
  </details>

    <!-- Part 2.4 -->
    <section id="p24" class="panel">
      <h2>Part 2.4 — Multiresolution Blending</h2>
      <p>I create Gaussian stacks for a binary mask and Laplacian stacks for the two images, then blend per level and collapse. I reproduce the oraple and try two custom blends, including one with an irregular mask.</p>
      <div class="grid g-3">
        <figure class="fig"><img class="wide zoomable" src="media/2.4_results_oraple.png" alt="Blend result 1" /><figcaption class="cap">Apple + Orange Horizontal Blend</figcaption></figure>
        <figure class="fig"><img class="wide zoomable" src="media/2.4_results_1.png" alt="Blend result 1" /><figcaption class="cap">Tiger + Bull Horizontal Blend </figcaption></figure>
        <figure class="fig"><img class="wide zoomable" src="media/2.4_results_2.png" alt="Blend result 2 (irregular mask)" /><figcaption class="cap">Tiger + Bull Wave Blend</figcaption></figure>
      </div>
   
<details>
  <summary><strong>Code — Part 2.4 Blending and Irregular Mask</strong></summary>
  <pre><code class="language-python">def blend_multires(im1, im2, mask, levels=6, sigma=2):
    guassian_stack1, laplacian_stack1 = get_gaussian_stack(im1, levels, sigma), get_laplacian_stack(im1, levels, sigma)[1]
    guassian_stack2, laplacian_stack2 = get_gaussian_stack(im2, levels, sigma), get_laplacian_stack(im2, levels, sigma)[1]
    guassian_stack_mask = get_gaussian_stack(mask, levels, sigma) 

    blends = [guassian_stack_mask[i]*laplacian_stack1[i] + (1.0 - guassian_stack_mask[i])*laplacian_stack2[i] for i in range(levels)]
    out = blends[-1].copy()
    for i in range(levels-2, -1, -1):
        out = out + blends[i]
    return np.clip(out, 0.0, 1.0)

    B = plt.imread('orange.jpeg') / 255.0
    A = plt.imread('apple.jpeg') / 255.0
    
    h = min(A.shape[0], B.shape[0])
    w = min(A.shape[1], B.shape[1])
    
    A = A[:h,:w]
    B = B[:h,:w]
    
    mask = get_horizontal_mask(A)
    out = blend_multires(A, B, mask, 6, 5)
</code></pre>
</details>
    </section>

    <section class="panel">
      <h2>Most Important Takeaway</h2>
      <p>In both edge detection and blending, <strong>frequency‑aware smoothing</strong> (Gaussian/DoG and mask pyramids) is the key to suppressing noise and seams while preserving perceptually salient structure.</p>
    </section>

    <section class="panel">
      <h2>Deliverables Checklist</h2>
      <ul>
        <li>1.1 Convolution (numpy‑only) + comparison to SciPy; boundary/runtime notes.</li>
        <li>1.2 Partial derivatives, gradient magnitude, binarized edge image (threshold choice justified).</li>
        <li>1.3 Gaussian construction, DoG filters visualized, results vs finite differences.</li>
        <li>2.1 Unsharp mask on Taj + one other; vary amount; show blurred/high‑freq/sharpened.</li>
        <li>2.2 Three hybrids (Derek+Nutmeg + two originals); one with FT visualizations.</li>
        <li>2.3/2.4 Gaussian & Laplacian stacks visualized; Oraple reproduction; two custom blends (one irregular mask).</li>
        <li>Clarity: organized webpage with captions and concise explanations.</li>
      </ul>
    </section>

    <footer>
      <p>© <span id="year"></span> Eduardo • Project 2: Fun with Filters & Frequencies</p>
      <p class="ai-ack">AI acknowledgment: I used ChatGPT (GPT-5 Thinking) to help draft this HTML/CSS template and organize content. All experiments, code, images, offsets, and write-up are my own; I reviewed and verified technical details.</p>
    </footer>
  </main>
</body>
</html>
